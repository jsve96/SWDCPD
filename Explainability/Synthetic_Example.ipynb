{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(d,N,seed,ndrift):\n",
    "    np.random.seed(seed)\n",
    "    #### generate random mean\n",
    "    mu1 = np.random.randn(d)\n",
    "    #sample random indicies\n",
    "    ind = list(np.random.choice(np.arange(0,d),ndrift,replace=False))\n",
    "    severity = np.random.normal(2,1,ndrift)\n",
    "    print(severity)\n",
    "    mu2 = mu1.copy()\n",
    "    mu2[ind] = mu2[ind] + severity\n",
    "\n",
    "    Sigma = np.eye(d)\n",
    "    Sigma_y = Sigma.copy()\n",
    "    Sigma_y[0,0] = 1\n",
    "    X = np.random.multivariate_normal(mu1,Sigma,size=N)\n",
    "    Y = np.random.multivariate_normal(mu2,Sigma_y,size=N)\n",
    "    return ind,severity, X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drifted_ind, severity, X,Y = generateData(50,1000,0,10)\n",
    "# beta_overall = []\n",
    "# SWDs_overall = []\n",
    "# fig,ax = plt.subplots(2,1,figsize=(12,8))\n",
    "# for _ in range(10):\n",
    "#     drifted_ind, severity, X,Y = generateData(20,1000,_,10)\n",
    "#     removed, betas,SWDs,_ = remove_important_features_syn(X,Y,15,N_Theta=1000)\n",
    "#     beta_overall.append(betas)\n",
    "#     SWDs_overall.append(SWDs)\n",
    "#     ax[0].plot(range(len(betas)),betas,marker='.',color='grey',alpha=0.4)\n",
    "#     ax[1].plot(range(len(SWDs)),SWDs,marker='.',color='grey',alpha=0.4)\n",
    "\n",
    "# ax[0].plot(range(len(betas)),np.array(beta_overall).mean(axis=0),marker='.',color='red')\n",
    "\n",
    "# ax[1].plot(range(len(SWDs)),np.array(SWDs_overall).mean(axis=0),marker='.',color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.07042975  0.9495182   0.62380174  1.06918083  1.58137499 -0.05153057\n",
      "  2.95241103  2.8860449   0.96727365  3.33933427]\n"
     ]
    }
   ],
   "source": [
    "###  generate_train_data\n",
    "N=10000\n",
    "drifted_ind, severity, X1,X2 = generateData(d=20,N=N,seed=404,ndrift=10)\n",
    "\n",
    "X1_train_val = X1.copy()\n",
    "X1_train_val_label = np.ones(len(X1_train_val))\n",
    "\n",
    "X2_train_val = X2.copy()\n",
    "X2_train_val_label = np.zeros(len(X2_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.96747666 1.42143353 1.56826515]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def generateData(d, N, seed, ndrift):\n",
    "    np.random.seed(seed)\n",
    "    mu1 = np.random.randn(d)\n",
    "    ind = list(np.random.choice(np.arange(0, d), ndrift, replace=False))\n",
    "    severity = np.random.normal(2, 1, ndrift)\n",
    "    print(severity)\n",
    "    mu2 = mu1.copy()\n",
    "    mu2[ind] = mu2[ind] + severity\n",
    "\n",
    "    Sigma = np.eye(d)\n",
    "    Sigma_y = Sigma.copy()\n",
    "    #Sigma_y[0, 0] = 1\n",
    "    X = np.random.multivariate_normal(mu1, Sigma, size=N)\n",
    "    Y = np.random.multivariate_normal(mu2, Sigma_y, size=N)\n",
    "    return ind, severity, X, Y\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, d, N, seed, ndrift):\n",
    "        # Generate data\n",
    "        self.ind, self.severity, self.X, self.Y = generateData(d, N, seed, ndrift)\n",
    "        # Convert data to torch tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(self.Y, dtype=torch.float32)\n",
    "        \n",
    "        # Labels: 0 for X samples, 1 for Y samples\n",
    "        self.labels_X = torch.zeros(len(self.X), dtype=torch.long)\n",
    "        self.labels_Y = torch.ones(len(self.Y), dtype=torch.long)\n",
    "        \n",
    "        # Combine X and Y with their respective labels\n",
    "        self.data = torch.cat((self.X, self.Y), dim=0)\n",
    "        self.labels = torch.cat((self.labels_X, self.labels_Y), dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total number of samples (sum of X and Y samples)\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a sample and its label as a tuple\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Example usage\n",
    "d = 10   # Number of dimensions\n",
    "N = 5000       # Number of samples per class\n",
    "seed = 44     # Random seed\n",
    "ndrift = 3    # Number of drift dimensions\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = SyntheticDataset(d, N, seed, ndrift)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size - int(0.1 * len(dataset))\n",
    "test_size = int(0.1*len(dataset))\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset=dataset, lengths=[train_size, val_size,test_size])\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "# # Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Iterate over DataLoader\n",
    "# for data_batch, label_batch in dataloader:\n",
    "#     print(\"Data batch:\", data_batch)\n",
    "#     print(\"Label batch:\", label_batch)\n",
    "#     break  # Just display one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        # self.fc1 = nn.Linear(input_dim, 64)    # First fully connected layer\n",
    "        # self.fc2 = nn.Linear(64, 32)           # Second fully connected layer\n",
    "        # self.fc3 = nn.Linear(32, 1)            # Output layer for binary classification\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Increased to 128 units\n",
    "        self.fc2 = nn.Linear(128, 64)         # Increased to 64 units\n",
    "        self.fc3 = nn.Linear(64, 32)          # Additional hidden layer\n",
    "        self.fc4 = nn.Linear(32, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()            # Sigmoid for binary output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))          # Sigmoid activation for the output\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for data_batch, label_batch in dataloader:\n",
    "            # Move inputs and labels to device if GPU is used\n",
    "            label_batch = label_batch.float().unsqueeze(1)  # Reshape for BCELoss\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss for display\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print the average loss for this epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:13,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train loss:  0.25372| Train acc:  0.89988| Val loss:  0.20791| Val acc:  0.92460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:10,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1| Train loss:  0.20252| Train acc:  0.91775| Val loss:  0.20030| Val acc:  0.91766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:08,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2| Train loss:  0.20032| Train acc:  0.91825| Val loss:  0.19252| Val acc:  0.92460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:07,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3| Train loss:  0.19450| Train acc:  0.92200| Val loss:  0.18897| Val acc:  0.92262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:06<00:05,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4| Train loss:  0.19079| Train acc:  0.92388| Val loss:  0.18526| Val acc:  0.92262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:09<00:07,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5| Train loss:  0.18914| Train acc:  0.92438| Val loss:  0.18834| Val acc:  0.92659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:13<00:07,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6| Train loss:  0.18454| Train acc:  0.92738| Val loss:  0.18766| Val acc:  0.92262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:17<00:05,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7| Train loss:  0.18330| Train acc:  0.92625| Val loss:  0.21026| Val acc:  0.92758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:20<00:03,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8| Train loss:  0.18140| Train acc:  0.92963| Val loss:  0.18108| Val acc:  0.93056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9| Train loss:  0.17936| Train acc:  0.92838| Val loss:  0.18790| Val acc:  0.92460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "input_dim = d   # Number of features from the dataset\n",
    "model_NN1 = ClassificationNet(input_dim)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "accuracy = BinaryAccuracy()\n",
    "#optimizer = optim.SGD(model_NN1.parameters(), lr=0.001,momentum=0.9)\n",
    "optimizer = optim.Adam(model_NN1.parameters(),lr=0.001)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Experiment tracking\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "experiment_name = \"Synthetic\"\n",
    "model_name = \"NN1\"\n",
    "log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# device-agnostic setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "accuracy = accuracy.to(device)\n",
    "model_NN1 = model_NN1.to(device)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Training loop\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.float().to(device)\n",
    "        \n",
    "        model_NN1.train()\n",
    "        \n",
    "        y_pred = model_NN1(X)\n",
    "        loss = loss_fn(y_pred, y.unsqueeze(1))\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        acc = accuracy(y_pred, y.unsqueeze(1))\n",
    "        train_acc += acc\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "        \n",
    "    # Validation loop\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    model_NN1.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in val_dataloader:\n",
    "            X, y = X.to(device), y.float().to(device)\n",
    "        \n",
    "            y_pred = model_NN1(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            acc = accuracy(y_pred, y.unsqueeze(1))\n",
    "            val_acc += acc\n",
    "            \n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_acc /= len(val_dataloader)\n",
    "        \n",
    "    writer.add_scalars(main_tag=\"Loss\", tag_scalar_dict={\"train/loss\": train_loss, \"val/loss\": val_loss}, global_step=epoch)\n",
    "    writer.add_scalars(main_tag=\"Accuracy\", tag_scalar_dict={\"train/acc\": train_acc, \"val/acc\": val_acc}, global_step=epoch)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}| Train loss: {train_loss: .5f}| Train acc: {train_acc: .5f}| Val loss: {val_loss: .5f}| Val acc: {val_acc: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight torch.Size([128, 10])\n",
      "fc1.bias torch.Size([128])\n",
      "fc2.weight torch.Size([64, 128])\n",
      "fc2.bias torch.Size([64])\n",
      "fc3.weight torch.Size([32, 64])\n",
      "fc3.bias torch.Size([32])\n",
      "fc4.weight torch.Size([1, 32])\n",
      "fc4.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_NN1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.19221| Test acc:  0.91369\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "loss_fn = nn.BCELoss().to(device)\n",
    "accuracy = BinaryAccuracy().to(device)\n",
    "\n",
    "test_loss, test_acc = 0, 0\n",
    "\n",
    "#model_lenet5_v1_mnist_loaded.to(device)\n",
    "model_NN1.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.float().to(device)\n",
    "        y_pred = model_NN1(X)\n",
    "        \n",
    "        test_loss += loss_fn(y_pred, y.unsqueeze(1))\n",
    "        test_acc += accuracy(y_pred, y.unsqueeze(1))\n",
    "        \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "print(f\"Test loss: {test_loss: .5f}| Test acc: {test_acc: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.9657e-01],\n",
       "        [9.9636e-01],\n",
       "        [9.9992e-01],\n",
       "        [9.9718e-01],\n",
       "        [9.8691e-01],\n",
       "        [9.9902e-01],\n",
       "        [1.9469e-05],\n",
       "        [8.3124e-01],\n",
       "        [9.9939e-01],\n",
       "        [2.5167e-02],\n",
       "        [7.4609e-02],\n",
       "        [9.9961e-01],\n",
       "        [9.9497e-01],\n",
       "        [9.6825e-01],\n",
       "        [9.9999e-01],\n",
       "        [9.9786e-01]], device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationNet(\n",
       "  (fc1): Linear(in_features=10, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]c:\\Users\\Sven Jacob\\miniconda3\\envs\\torch\\Lib\\site-packages\\captum\\attr\\_core\\deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n",
      "100%|██████████| 63/63 [00:15<00:00,  4.16it/s]\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients, GradientShap, KernelShap, DeepLift\n",
    "from tqdm import tqdm\n",
    "ig = IntegratedGradients(model_NN1)\n",
    "gs = GradientShap(model_NN1)\n",
    "ks = KernelShap(model_NN1)\n",
    "dl = DeepLift(model_NN1)\n",
    "#sample ,label = test_dataset[10]\n",
    "\n",
    "#tensor_1 = torch.mean(torch.stack(data_c1),axis=0)\n",
    "#tensor_2 = torch.mean(torch.stack(data_c2),axis=0)\n",
    "\n",
    "all_attributions_ig = []\n",
    "all_labels = []\n",
    "all_attributions_gs = []\n",
    "all_attributions_ks = []\n",
    "all_attributions_dl = []\n",
    "model_NN1.eval()\n",
    "for batch_samples, batch_labels in tqdm(test_dataloader):\n",
    "    # Ensure samples have the correct shape\n",
    "    batch_samples = batch_samples.requires_grad_().to(device) # Enable gradients for attribution\n",
    "    batch_labels = batch_labels.to(device)\n",
    "    baseline_dist = torch.zeros((batch_samples.shape[0],input_dim)).to(device)\n",
    "    #baseline_dist = torch.abs(torch.tensor(Contributions[0],dtype=torch.float32).repeat(batch_samples.shape[0],1))\n",
    "\n",
    "    # Calculate the attributions for each sample in the batch\n",
    "    # We use target=0 as we are working with a binary classification output\n",
    "    attributions, deltas = ig.attribute(batch_samples, target=0, return_convergence_delta=True,n_steps=200)\n",
    "\n",
    "    \n",
    "    # Append attributions and labels for further analysis\n",
    "    all_attributions_ig.append(attributions)\n",
    "    all_labels.append(batch_labels)\n",
    "    #batch_samples = batch_samples.requires_grad_()\n",
    "    attributions_gs, deltas = gs.attribute(batch_samples, target=0,  baselines=baseline_dist,return_convergence_delta=True,n_samples=50)\n",
    "    all_attributions_gs.append(attributions_gs)\n",
    "    \n",
    "    #batch_samples = batch_samples.requires_grad_()\n",
    "    attributions_dl = dl.attribute(batch_samples, target=0)\n",
    "    all_attributions_dl.append(attributions_dl)\n",
    "\n",
    "\n",
    "# Concatenate all attributions and labels\n",
    "all_attributions_ig = torch.cat(all_attributions_ig, dim=0)  # Shape: [num_samples, num_features]\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "all_attributions_gs = torch.cat(all_attributions_gs, dim=0)\n",
    "all_attributions_dl = torch.cat(all_attributions_dl, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 2]\n",
      "SWD: 0.7843804950088487\n",
      "[[ 2.89801657e-02  7.79731914e-03 -3.90339366e-01 -5.93848677e-03\n",
      "  -3.71647543e-03 -4.13291032e-02 -2.66091065e-04  3.09379135e-02\n",
      "  -4.46659577e-01 -3.40958562e-01]\n",
      " [-3.10355549e-02  1.78349620e-02  3.56376198e-01 -2.14387747e-02\n",
      "   1.89065720e-02  7.26934919e-03  2.83791031e-04 -1.89399604e-02\n",
      "   4.75221231e-01  3.31032961e-01]]\n",
      "[ 2.89801657e-02  7.79731914e-03 -3.90339366e-01 -5.93848677e-03\n",
      " -3.71647543e-03 -4.13291032e-02 -2.66091065e-04  3.09379135e-02\n",
      " -4.46659577e-01 -3.40958562e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sven Jacob\\miniconda3\\envs\\torch\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWD: 0.8099925058586964\n",
      "[[-2.19657350e-02 -1.03333286e-02  3.62588541e-01  1.39690362e-04\n",
      "  -3.09248392e-03  3.07177992e-02  3.79241194e-03 -2.81162754e-03\n",
      "   4.81743972e-01  3.38262134e-01]\n",
      " [ 4.81802766e-02  2.48360383e-04 -3.57214974e-01 -3.51996698e-03\n",
      "   1.13684635e-02 -9.49436247e-03 -1.82097785e-02 -7.82767282e-03\n",
      "  -4.86582055e-01 -3.39203279e-01]]\n",
      "[-2.19657350e-02 -1.03333286e-02  3.62588541e-01  1.39690362e-04\n",
      " -3.09248392e-03  3.07177992e-02  3.79241194e-03 -2.81162754e-03\n",
      "  4.81743972e-01  3.38262134e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sven Jacob\\miniconda3\\envs\\torch\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWD: 0.4453589788543815\n",
      "[[ 0.01634685 -0.04156733 -0.51624926 -0.02128208 -0.02650944  0.01628856\n",
      "  -0.03270505 -0.01208056  0.02038258 -0.44341165]\n",
      " [ 0.0066706   0.01355128  0.51050804 -0.00097566 -0.00704671  0.00269326\n",
      "  -0.00066483 -0.01717633 -0.00706206  0.44836178]]\n",
      "[ 0.01634685 -0.04156733 -0.51624926 -0.02128208 -0.02650944  0.01628856\n",
      " -0.03270505 -0.01208056  0.02038258 -0.44341165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sven Jacob\\miniconda3\\envs\\torch\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "\n",
    "Syn_samples = []\n",
    "\n",
    "all_labels = []\n",
    "for batch_samples, batch_labels in test_dataloader:\n",
    "    Syn_samples.append(batch_samples)\n",
    "    all_labels.append(batch_labels)\n",
    "\n",
    "\n",
    "Syn_samples = torch.cat(Syn_samples, dim=0)\n",
    "all_labels = torch.cat(all_labels,dim=0)\n",
    "\n",
    "Syn_X = Syn_samples[all_labels==0].numpy()\n",
    "Syn_Y = Syn_samples[all_labels==1].numpy()\n",
    "\n",
    "print(dataset.ind)\n",
    "rf, betas, SWDs , Contributions = remove_important_features_syn(Syn_X,Syn_Y,3,10000,max_parameter=False,q=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "contributions_plot = np.abs((Contributions)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars = tuple([str(i) for i in range(d)])\n",
    "ig_plot = torch.abs(all_attributions_ig[all_labels ==0 ].mean(axis=0)-all_attributions_ig[all_labels ==1 ].mean(axis=0)).detach().cpu().numpy()\n",
    "gs_plot = torch.abs(all_attributions_gs[all_labels ==0 ].mean(axis=0)-all_attributions_gs[all_labels ==1 ].mean(axis=0)).detach().cpu().numpy()\n",
    "dl_plot = torch.abs(all_attributions_dl[all_labels ==0 ].mean(axis=0)-all_attributions_dl[all_labels ==1 ].mean(axis=0)).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01783957, -0.03639256, -0.37608461, -0.01454402,  0.00594951,\n",
       "        -0.0098662 ,  0.01113785,  0.01084753, -0.46738715, -0.32929304]),\n",
       " array([ 0.00181259,  0.00520202,  0.36193348,  0.01002458, -0.00800981,\n",
       "         0.02463911, -0.00638874,  0.01784618,  0.48197824,  0.32655414]),\n",
       " array([ 0.00627071, -0.00314288, -0.50346801,  0.00923644,  0.02881554,\n",
       "         0.00493313, -0.04081449, -0.03270971,  0.01488048, -0.48107194])]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.ticker as ticker\n",
    "\n",
    "data = {\n",
    "    'Features': list(bars),\n",
    "    'IG': ig_plot,\n",
    "    'GS': gs_plot,\n",
    "    'DL': dl_plot,\n",
    "    'swd_group': np.abs(Contributions[0]) # This will be plotted on the secondary y-axis\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.set_index('Features', inplace=True)\n",
    "\n",
    "# Plot settings\n",
    "bar_width = 0.2  # Width of each bar\n",
    "x = np.arange(len(df))  # X positions for the features\n",
    "plt.rcParams['hatch.linewidth'] = 1  # Default is 1.0\n",
    "#hatch_patterns = ['..', '..', '..']  # Hatches for the first 3 groups\n",
    "hatch_patterns = ['', '', '']\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot the first three groups with hatches on the primary y-axis\n",
    "colors = [plt.colormaps.get_cmap('tab20c')(18),plt.colormaps.get_cmap('tab20c')(17),plt.colormaps.get_cmap('tab20c')(16)]\n",
    "for i, (group, hatch) in enumerate(zip(df.columns[:-1], hatch_patterns)):  # Exclude 'Group 4'\n",
    "    ax.bar(x + i * bar_width, df[group], bar_width, label=group, hatch=hatch,color=colors[i],edgecolor='black',lw=2,alpha=1)\n",
    "\n",
    "# Create a secondary y-axis for 'Group 4'\n",
    "ax2 = ax.twinx()\n",
    "ax2.bar(x + 3 * bar_width, df['swd_group'], bar_width, label='SWD', color='blue',edgecolor='black',lw=2,alpha=0.9)\n",
    "\n",
    "# Customizations for primary y-axis\n",
    "#ax.set_ylabel('Values (Groups 1-3)')\n",
    "ax.set_xticks(x + bar_width * 1.5)  # Align x-axis labels to the center of the groups\n",
    "ax.set_xticklabels(df.index)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "for i in dataset.ind:\n",
    "    ax.xaxis.get_ticklabels()[i].set_bbox(dict(facecolor='none',edgecolor='red'))\n",
    "\n",
    "ax.set_xlabel('Features')\n",
    "ax.yaxis.set_major_formatter(ticker.ScalarFormatter(useMathText=True))\n",
    "ax.ticklabel_format(style='sci', axis='y', scilimits=(0, 0))\n",
    "# Customizations for secondary y-axis\n",
    "#ax2.set_ylabel(color='lightcoral')\n",
    "ax2.legend(loc='upper right', frameon=True)\n",
    "\n",
    "# Aligning grid and layout\n",
    "plt.title('Explanation scores')\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('Syn_Experiment1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8686595600041314"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim = lambda a,b : np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "cos_sim(data['swd_group'],dl_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[152], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m test_dataloader:\n\u001b[0;32m     19\u001b[0m     REPORT[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m---> 20\u001b[0m     x,y \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m, y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m#target = torch.abs(y-1)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     x_fgm \u001b[38;5;241m=\u001b[39m fast_gradient_method(model_NN1,x,eps,norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "\n",
    "\n",
    "#model_loaded = model_NN1\n",
    "\n",
    "model_NN1.eval()\n",
    "epsilons = [1]\n",
    "accuracies = []\n",
    "#eps = 0.0005\n",
    "REPORTS= []\n",
    "for eps in epsilons:\n",
    "    nb_missclassified_FGSM=0\n",
    "    nb_missclassified_PGD=0\n",
    "\n",
    "    REPORT = {'original':{'y':[],'x':[]},'attack_FGSM':{'y':[],'x':[]},'attack_PGD':{'y':[],'x':[]}}\n",
    "    #torch.manual_seed(10)\n",
    "    for x,y in test_dataloader:\n",
    "        REPORT['original']['x'].append(x)\n",
    "        x,y = x.to(device), y.to(device)\n",
    "        #target = torch.abs(y-1)\n",
    "        x_fgm = fast_gradient_method(model_NN1,x,eps,norm=2)\n",
    "        REPORT['attack_FGSM']['x'].append(x_fgm.detach().cpu())\n",
    "\n",
    "       # x_pgd = projected_gradient_descent(model_loaded,x,eps, eps_iter=0.0001, nb_iter=40, norm=2)\n",
    "        #REPORT['attack_PGD']['x'].append(x_pgd.detach().cpu())\n",
    "\n",
    "\n",
    "        _, y_pred = model_NN1(x).max(1)\n",
    "        REPORT['original']['y'].append(y.detach().cpu())\n",
    "\n",
    "        _, y_pred_fgm = model_NN1(x_fgm).max(1)\n",
    "        REPORT['attack_FGSM']['y'].append(y_pred_fgm.detach().cpu())\n",
    "\n",
    "        #_, y_pred_pgd = model_loaded(x_pgd).max(1)\n",
    "        #REPORT['attack_PGD']['y'].append(y_pred_pgd.detach().cpu())\n",
    "\n",
    "     \n",
    "\n",
    "        nb_missclassified_FGSM+= torch.sum((y_pred_fgm == y_pred))\n",
    "        #nb_missclassified_PGD+= torch.sum((y_pred_pgd == y_pred))\n",
    "\n",
    "    REPORT['original']['y'] = torch.cat(REPORT['original']['y'],axis=0)\n",
    "    REPORT['original']['x'] = torch.cat(REPORT['original']['x'],axis=0)\n",
    "\n",
    "    REPORT['attack_FGSM']['y'] = torch.cat(REPORT['attack_FGSM']['y'],axis=0)\n",
    "    REPORT['attack_FGSM']['x'] = torch.cat(REPORT['attack_FGSM']['x'],axis=0)\n",
    "\n",
    "    #REPORT['attack_PGD']['y'] = torch.cat(REPORT['attack_PGD']['y'],axis=0)\n",
    "    #REPORT['attack_PGD']['x'] = torch.cat(REPORT['attack_PGD']['x'],axis=0)\n",
    "    acc_FGSM = nb_missclassified_FGSM.detach().cpu().numpy()/len(test_dataset)\n",
    "    #acc_PGD = nb_missclassified_PGD.detach().cpu().numpy()/len(test_dataset)\n",
    "\n",
    "    accuracies.append(acc_FGSM)\n",
    "    print(eps,acc_FGSM)\n",
    "    #print(eps, acc_PGD)\n",
    "\n",
    "    REPORTS.append(REPORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FGSM attack function\n",
    "def fgsm_attack(model, criterion, inputs, labels, epsilon):\n",
    "    \"\"\"\n",
    "    Performs FGSM attack on the input samples.\n",
    "\n",
    "    Args:\n",
    "        model: The neural network model\n",
    "        criterion: Loss function used for training\n",
    "        inputs: Original input data (torch.Tensor)\n",
    "        labels: True labels corresponding to the inputs\n",
    "        epsilon: Perturbation magnitude (float)\n",
    "    \n",
    "    Returns:\n",
    "        perturbed_inputs: Adversarial examples created by FGSM\n",
    "    \"\"\"\n",
    "    # Ensure input requires gradient for FGSM\n",
    "    inputs.requires_grad = True\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass to compute gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Compute the sign of the gradients\n",
    "    data_grad = inputs.grad.data\n",
    "    sign_data_grad = data_grad.sign()\n",
    "\n",
    "    # Create perturbed input\n",
    "    perturbed_inputs = inputs + epsilon * sign_data_grad\n",
    "    perturbed_inputs = torch.clamp(perturbed_inputs, 0, 1)  # Clamp to valid range (optional)\n",
    "\n",
    "    return perturbed_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 10\tTest Accuracy = 47.30%\n"
     ]
    }
   ],
   "source": [
    "epsilon = 10  # Choose an epsilon value\n",
    "criterion = nn.BCELoss()  # Binary cross-entropy loss\n",
    "\n",
    "model_NN1.eval()  # Set the model to evaluation mode\n",
    "\n",
    "correct = 0\n",
    "adv_examples = []\n",
    "\n",
    "for data, target in test_dataloader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "\n",
    "    # Convert target to match the output size for BCE Loss\n",
    "    target = target.view(-1, 1).float()\n",
    "\n",
    "    # Generate adversarial examples\n",
    "    perturbed_data = fgsm_attack(model_NN1, criterion, data, target, epsilon)\n",
    "\n",
    "    # Re-evaluate the model with perturbed data\n",
    "    output = model_NN1(perturbed_data)\n",
    "    pred = (output > 0.5).float()  # Binary prediction\n",
    "\n",
    "    # Track accuracy\n",
    "    correct += (pred == target).sum().item()\n",
    "    \n",
    "\n",
    "    # Optionally, save adversarial examples\n",
    "    for i in range(data.size(0)):  # Iterate over batch\n",
    "        if pred[i] != target[i]:  # Check if attack was successful\n",
    "            adv_examples.append((data[i].detach().cpu(), perturbed_data[i].detach().cpu()))\n",
    "    \n",
    "\n",
    "# Calculate final accuracy\n",
    "final_acc = correct / len(test_dataloader.dataset)\n",
    "print(f\"Epsilon: {epsilon}\\tTest Accuracy = {final_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.zeros(10).to(device)\n",
    "\n",
    "for i in range(len(adv_examples)):\n",
    "    l+=torch.abs(adv_examples[i][0]-adv_examples[i][1]).mean(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.9353,  0.8520,  2.5920, -1.1417, -1.3757, -2.5052,  1.6496, -0.0100,\n",
       "         1.1052,  0.3070])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_examples[0][0]-adv_examples[0][1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
