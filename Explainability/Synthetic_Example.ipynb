{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(d,N,seed,ndrift):\n",
    "    np.random.seed(seed)\n",
    "    #### generate random mean\n",
    "    mu1 = np.random.randn(d)\n",
    "    #sample random indicies\n",
    "    ind = list(np.random.choice(np.arange(0,d),ndrift,replace=False))\n",
    "    severity = np.random.normal(2,1,ndrift)\n",
    "    print(severity)\n",
    "    mu2 = mu1.copy()\n",
    "    mu2[ind] = mu2[ind] + severity\n",
    "\n",
    "    Sigma = np.eye(d)\n",
    "    Sigma_y = Sigma.copy()\n",
    "    Sigma_y[0,0] = 1\n",
    "    X = np.random.multivariate_normal(mu1,Sigma,size=N)\n",
    "    Y = np.random.multivariate_normal(mu2,Sigma_y,size=N)\n",
    "    return ind,severity, X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drifted_ind, severity, X,Y = generateData(50,1000,0,10)\n",
    "# beta_overall = []\n",
    "# SWDs_overall = []\n",
    "# fig,ax = plt.subplots(2,1,figsize=(12,8))\n",
    "# for _ in range(10):\n",
    "#     drifted_ind, severity, X,Y = generateData(20,1000,_,10)\n",
    "#     removed, betas,SWDs,_ = remove_important_features_syn(X,Y,15,N_Theta=1000)\n",
    "#     beta_overall.append(betas)\n",
    "#     SWDs_overall.append(SWDs)\n",
    "#     ax[0].plot(range(len(betas)),betas,marker='.',color='grey',alpha=0.4)\n",
    "#     ax[1].plot(range(len(SWDs)),SWDs,marker='.',color='grey',alpha=0.4)\n",
    "\n",
    "# ax[0].plot(range(len(betas)),np.array(beta_overall).mean(axis=0),marker='.',color='red')\n",
    "\n",
    "# ax[1].plot(range(len(SWDs)),np.array(SWDs_overall).mean(axis=0),marker='.',color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.07042975  0.9495182   0.62380174  1.06918083  1.58137499 -0.05153057\n",
      "  2.95241103  2.8860449   0.96727365  3.33933427]\n"
     ]
    }
   ],
   "source": [
    "###  generate_train_data\n",
    "N=10000\n",
    "drifted_ind, severity, X1,X2 = generateData(d=20,N=N,seed=404,ndrift=10)\n",
    "\n",
    "X1_train_val = X1.copy()\n",
    "X1_train_val_label = np.ones(len(X1_train_val))\n",
    "\n",
    "X2_train_val = X2.copy()\n",
    "X2_train_val_label = np.zeros(len(X2_train_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.96747666 1.42143353 1.56826515]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def generateData(d, N, seed, ndrift):\n",
    "    np.random.seed(seed)\n",
    "    mu1 = np.random.randn(d)\n",
    "    ind = list(np.random.choice(np.arange(0, d), ndrift, replace=False))\n",
    "    severity = np.random.normal(2, 1, ndrift)\n",
    "    print(severity)\n",
    "    mu2 = mu1.copy()\n",
    "    mu2[ind] = mu2[ind] + severity\n",
    "\n",
    "    Sigma = np.eye(d)\n",
    "    Sigma_y = Sigma.copy()\n",
    "    #Sigma_y[0, 0] = 1\n",
    "    X = np.random.multivariate_normal(mu1, Sigma, size=N)\n",
    "    Y = np.random.multivariate_normal(mu2, Sigma_y, size=N)\n",
    "    return ind, severity, X, Y\n",
    "\n",
    "class SyntheticDataset(Dataset):\n",
    "    def __init__(self, d, N, seed, ndrift):\n",
    "        # Generate data\n",
    "        self.ind, self.severity, self.X, self.Y = generateData(d, N, seed, ndrift)\n",
    "        # Convert data to torch tensors\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(self.Y, dtype=torch.float32)\n",
    "        \n",
    "        # Labels: 0 for X samples, 1 for Y samples\n",
    "        self.labels_X = torch.zeros(len(self.X), dtype=torch.long)\n",
    "        self.labels_Y = torch.ones(len(self.Y), dtype=torch.long)\n",
    "        \n",
    "        # Combine X and Y with their respective labels\n",
    "        self.data = torch.cat((self.X, self.Y), dim=0)\n",
    "        self.labels = torch.cat((self.labels_X, self.labels_Y), dim=0)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Total number of samples (sum of X and Y samples)\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a sample and its label as a tuple\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# Example usage\n",
    "d = 10    # Number of dimensions\n",
    "N = 5000       # Number of samples per class\n",
    "seed = 44     # Random seed\n",
    "ndrift = 3    # Number of drift dimensions\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = SyntheticDataset(d, N, seed, ndrift)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size - int(0.1 * len(dataset))\n",
    "test_size = int(0.1*len(dataset))\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset=dataset, lengths=[train_size, val_size,test_size])\n",
    "\n",
    "len(train_dataset), len(val_dataset), len(test_dataset)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "# # Create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# # Iterate over DataLoader\n",
    "# for data_batch, label_batch in dataloader:\n",
    "#     print(\"Data batch:\", data_batch)\n",
    "#     print(\"Label batch:\", label_batch)\n",
    "#     break  # Just display one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class ClassificationNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(ClassificationNet, self).__init__()\n",
    "        # self.fc1 = nn.Linear(input_dim, 64)    # First fully connected layer\n",
    "        # self.fc2 = nn.Linear(64, 32)           # Second fully connected layer\n",
    "        # self.fc3 = nn.Linear(32, 1)            # Output layer for binary classification\n",
    "        self.fc1 = nn.Linear(input_dim, 128)  # Increased to 128 units\n",
    "        self.fc2 = nn.Linear(128, 64)         # Increased to 64 units\n",
    "        self.fc3 = nn.Linear(64, 32)          # Additional hidden layer\n",
    "        self.fc4 = nn.Linear(32, 1)  \n",
    "        self.sigmoid = nn.Sigmoid()            # Sigmoid for binary output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.sigmoid(self.fc4(x))          # Sigmoid activation for the output\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()  # Set model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for data_batch, label_batch in dataloader:\n",
    "            # Move inputs and labels to device if GPU is used\n",
    "            label_batch = label_batch.float().unsqueeze(1)  # Reshape for BCELoss\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(data_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss for display\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print the average loss for this epoch\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:11,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Train loss:  0.52257| Train acc:  0.74150| Val loss:  0.29433| Val acc:  0.90278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:08,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1| Train loss:  0.23573| Train acc:  0.90812| Val loss:  0.21319| Val acc:  0.91567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:07,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2| Train loss:  0.20697| Train acc:  0.91712| Val loss:  0.20491| Val acc:  0.91964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:04<00:06,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3| Train loss:  0.19680| Train acc:  0.91913| Val loss:  0.19621| Val acc:  0.92460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:05<00:04,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4| Train loss:  0.19266| Train acc:  0.92313| Val loss:  0.19987| Val acc:  0.91667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:06<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5| Train loss:  0.18926| Train acc:  0.92375| Val loss:  0.19335| Val acc:  0.92262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:07<00:02,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6| Train loss:  0.18903| Train acc:  0.92263| Val loss:  0.19398| Val acc:  0.93056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:08<00:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7| Train loss:  0.18707| Train acc:  0.92450| Val loss:  0.19192| Val acc:  0.92857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:09<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8| Train loss:  0.18751| Train acc:  0.92338| Val loss:  0.18686| Val acc:  0.93056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:10<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9| Train loss:  0.18561| Train acc:  0.92600| Val loss:  0.19071| Val acc:  0.93452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torchmetrics.classification import BinaryAccuracy\n",
    "\n",
    "input_dim = d   # Number of features from the dataset\n",
    "model_NN1 = ClassificationNet(input_dim)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "accuracy = BinaryAccuracy()\n",
    "optimizer = optim.SGD(model_NN1.parameters(), lr=0.001,momentum=0.9)\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Experiment tracking\n",
    "timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "experiment_name = \"Synthetic\"\n",
    "model_name = \"NN1\"\n",
    "log_dir = os.path.join(\"runs\", timestamp, experiment_name, model_name)\n",
    "writer = SummaryWriter(log_dir)\n",
    "\n",
    "# device-agnostic setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "accuracy = accuracy.to(device)\n",
    "model_NN1 = model_NN1.to(device)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    # Training loop\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.to(device), y.float().to(device)\n",
    "        \n",
    "        model_NN1.train()\n",
    "        \n",
    "        y_pred = model_NN1(X)\n",
    "        loss = loss_fn(y_pred, y.unsqueeze(1))\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        acc = accuracy(y_pred, y.unsqueeze(1))\n",
    "        train_acc += acc\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "        \n",
    "    # Validation loop\n",
    "    val_loss, val_acc = 0.0, 0.0\n",
    "    model_NN1.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in val_dataloader:\n",
    "            X, y = X.to(device), y.float().to(device)\n",
    "        \n",
    "            y_pred = model_NN1(X)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y.unsqueeze(1))\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            acc = accuracy(y_pred, y.unsqueeze(1))\n",
    "            val_acc += acc\n",
    "            \n",
    "        val_loss /= len(val_dataloader)\n",
    "        val_acc /= len(val_dataloader)\n",
    "        \n",
    "    writer.add_scalars(main_tag=\"Loss\", tag_scalar_dict={\"train/loss\": train_loss, \"val/loss\": val_loss}, global_step=epoch)\n",
    "    writer.add_scalars(main_tag=\"Accuracy\", tag_scalar_dict={\"train/acc\": train_acc, \"val/acc\": val_acc}, global_step=epoch)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}| Train loss: {train_loss: .5f}| Train acc: {train_acc: .5f}| Val loss: {val_loss: .5f}| Val acc: {val_acc: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight torch.Size([128, 10])\n",
      "fc1.bias torch.Size([128])\n",
      "fc2.weight torch.Size([64, 128])\n",
      "fc2.bias torch.Size([64])\n",
      "fc3.weight torch.Size([32, 64])\n",
      "fc3.bias torch.Size([32])\n",
      "fc4.weight torch.Size([1, 32])\n",
      "fc4.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_NN1.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.20223| Test acc:  0.91766\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "accuracy = BinaryAccuracy()\n",
    "\n",
    "test_loss, test_acc = 0, 0\n",
    "\n",
    "#model_lenet5_v1_mnist_loaded.to(device)\n",
    "model_NN1.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.float().to(device)\n",
    "        y_pred = model_NN1(X)\n",
    "        \n",
    "        test_loss += loss_fn(y_pred, y.unsqueeze(1))\n",
    "        test_acc += accuracy(y_pred, y.unsqueeze(1))\n",
    "        \n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "print(f\"Test loss: {test_loss: .5f}| Test acc: {test_acc: .5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationNet(\n",
       "  (fc1): Linear(in_features=10, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\captum\\attr\\_core\\deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import IntegratedGradients, GradientShap, KernelShap, DeepLift\n",
    "\n",
    "ig = IntegratedGradients(model_NN1)\n",
    "gs = GradientShap(model_NN1)\n",
    "ks = KernelShap(model_NN1)\n",
    "dl = DeepLift(model_NN1)\n",
    "#sample ,label = test_dataset[10]\n",
    "\n",
    "#tensor_1 = torch.mean(torch.stack(data_c1),axis=0)\n",
    "#tensor_2 = torch.mean(torch.stack(data_c2),axis=0)\n",
    "\n",
    "all_attributions_ig = []\n",
    "all_labels = []\n",
    "all_attributions_gs = []\n",
    "all_attributions_ks = []\n",
    "all_attributions_dl = []\n",
    "\n",
    "for batch_samples, batch_labels in test_dataloader:\n",
    "    # Ensure samples have the correct shape\n",
    "    batch_samples = batch_samples.requires_grad_()  # Enable gradients for attribution\n",
    "    baseline_dist = torch.zeros((batch_samples.shape[0],input_dim))\n",
    "    #baseline_dist = torch.abs(torch.tensor(Contributions[0],dtype=torch.float32).repeat(batch_samples.shape[0],1))\n",
    "\n",
    "    # Calculate the attributions for each sample in the batch\n",
    "    # We use target=0 as we are working with a binary classification output\n",
    "    attributions, deltas = ig.attribute(batch_samples, target=0, return_convergence_delta=True)\n",
    "\n",
    "    \n",
    "    # Append attributions and labels for further analysis\n",
    "    all_attributions_ig.append(attributions)\n",
    "    all_labels.append(batch_labels)\n",
    "    #batch_samples = batch_samples.requires_grad_()\n",
    "    attributions_gs, deltas = gs.attribute(batch_samples, target=0,  baselines=baseline_dist,return_convergence_delta=True)\n",
    "    all_attributions_gs.append(attributions_gs)\n",
    "    \n",
    "    #batch_samples = batch_samples.requires_grad_()\n",
    "    attributions_dl = dl.attribute(batch_samples, target=0)\n",
    "    all_attributions_dl.append(attributions_dl)\n",
    "\n",
    "\n",
    "# Concatenate all attributions and labels\n",
    "all_attributions_ig = torch.cat(all_attributions_ig, dim=0)  # Shape: [num_samples, num_features]\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "all_attributions_gs = torch.cat(all_attributions_gs, dim=0)\n",
    "all_attributions_dl = torch.cat(all_attributions_dl, dim=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 2]\n",
      "SWD: 0.8093727041952168\n",
      "[[ 0.01770071 -0.00598727  0.39146087  0.00250438 -0.04456042  0.05257728\n",
      "   0.03543146 -0.00650224  0.43839207  0.33618169]\n",
      " [-0.00332929  0.013214   -0.40456459  0.00238068  0.03486865 -0.02904393\n",
      "  -0.01357947 -0.01851592 -0.44214566 -0.32290977]]\n",
      "[ 0.01770071 -0.00598727  0.39146087  0.00250438 -0.04456042  0.05257728\n",
      "  0.03543146 -0.00650224  0.43839207  0.33618169]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWD: 0.48025677796618654\n",
      "[[ 0.00789169  0.00286994  0.51519357  0.01586882 -0.02791575  0.00886312\n",
      "   0.04276914  0.01146325 -0.037073    0.43982132]\n",
      " [-0.00484397 -0.0217033  -0.53277149  0.00276074  0.04159193 -0.03195092\n",
      "  -0.02332073  0.00570991  0.02608569 -0.42879963]]\n",
      "[ 0.00789169  0.00286994  0.51519357  0.01586882 -0.02791575  0.00886312\n",
      "  0.04276914  0.01146325 -0.037073    0.43982132]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SWD: 0.23237525936994516\n",
      "[[-2.46300606e-02  3.94095321e-02  6.79410557e-03 -1.81594937e-02\n",
      "   4.86498382e-02 -4.08877482e-02 -4.62102596e-02  7.45300457e-03\n",
      "  -1.70728338e-02 -6.74171954e-01]\n",
      " [ 1.32992419e-02 -1.56026910e-02  1.11276793e-02  2.55680357e-02\n",
      "  -3.51157197e-02  5.35933975e-02  3.48862834e-02 -2.37166710e-04\n",
      "  -6.63483443e-03  6.76647061e-01]]\n",
      "[-0.02463006  0.03940953  0.00679411 -0.01815949  0.04864984 -0.04088775\n",
      " -0.04621026  0.007453   -0.01707283 -0.67417195]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\envs\\torch\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "\n",
    "Syn_samples = []\n",
    "\n",
    "all_labels = []\n",
    "for batch_samples, batch_labels in test_dataloader:\n",
    "    Syn_samples.append(batch_samples)\n",
    "    all_labels.append(batch_labels)\n",
    "\n",
    "\n",
    "Syn_samples = torch.cat(Syn_samples, dim=0)\n",
    "all_labels = torch.cat(all_labels,dim=0)\n",
    "\n",
    "Syn_X = Syn_samples[all_labels==0].numpy()\n",
    "Syn_Y = Syn_samples[all_labels==1].numpy()\n",
    "\n",
    "print(dataset.ind)\n",
    "rf, betas, SWDs , Contributions = remove_important_features_syn(Syn_X,Syn_Y,3,10000,max_parameter=False,q=0.95)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "contributions_plot = np.abs((Contributions)).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars = tuple([str(i) for i in range(d)])\n",
    "ig_plot = torch.abs(all_attributions_ig[all_labels ==0 ].mean(axis=0)-all_attributions_ig[all_labels ==1 ].mean(axis=0)).detach().numpy()\n",
    "gs_plot = torch.abs(all_attributions_gs[all_labels ==0 ].mean(axis=0)-all_attributions_gs[all_labels ==1 ].mean(axis=0)).detach().numpy()\n",
    "dl_plot = torch.abs(all_attributions_dl[all_labels ==0 ].mean(axis=0)-all_attributions_dl[all_labels ==1 ].mean(axis=0)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.43984838, -0.47824501, -0.0036617 ,  0.00329671, -0.18359461,\n",
       "         0.02616959, -0.12166752,  0.00614444, -0.03128047,  0.03987045]),\n",
       " array([-0.4438008 , -0.47501027,  0.05716069, -0.01945878, -0.18853435,\n",
       "         0.01911711, -0.09931729, -0.00606956,  0.00378418, -0.00342632]),\n",
       " array([-0.43528106, -0.48214825, -0.01416876, -0.02842868, -0.18144298,\n",
       "         0.01383956, -0.09038715, -0.0140193 , -0.02087687,  0.00162387])]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = {\n",
    "    'Features': list(bars),\n",
    "    'IG': ig_plot,\n",
    "    'GS': gs_plot,\n",
    "    'DL': dl_plot,\n",
    "    'swd_group': np.abs(Contributions[0]) # This will be plotted on the secondary y-axis\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.set_index('Features', inplace=True)\n",
    "\n",
    "# Plot settings\n",
    "bar_width = 0.2  # Width of each bar\n",
    "x = np.arange(len(df))  # X positions for the features\n",
    "plt.rcParams['hatch.linewidth'] = 1  # Default is 1.0\n",
    "#hatch_patterns = ['..', '..', '..']  # Hatches for the first 3 groups\n",
    "hatch_patterns = ['', '', '']\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "# Plot the first three groups with hatches on the primary y-axis\n",
    "colors = [plt.colormaps.get_cmap('tab20c')(18),plt.colormaps.get_cmap('tab20c')(17),plt.colormaps.get_cmap('tab20c')(16)]\n",
    "for i, (group, hatch) in enumerate(zip(df.columns[:-1], hatch_patterns)):  # Exclude 'Group 4'\n",
    "    ax.bar(x + i * bar_width, df[group], bar_width, label=group, hatch=hatch,color=colors[i],edgecolor='black',lw=2,alpha=1)\n",
    "\n",
    "# Create a secondary y-axis for 'Group 4'\n",
    "ax2 = ax.twinx()\n",
    "ax2.bar(x + 3 * bar_width, df['swd_group'], bar_width, label='SWD', color='blue',edgecolor='black',lw=2,alpha=0.9)\n",
    "\n",
    "# Customizations for primary y-axis\n",
    "#ax.set_ylabel('Values (Groups 1-3)')\n",
    "ax.set_xticks(x + bar_width * 1.5)  # Align x-axis labels to the center of the groups\n",
    "ax.set_xticklabels(df.index)\n",
    "ax.legend(loc='upper left')\n",
    "\n",
    "for i in dataset.ind:\n",
    "    ax.xaxis.get_ticklabels()[i].set_bbox(dict(facecolor='none',edgecolor='red'))\n",
    "\n",
    "ax.set_xlabel('Features')\n",
    "# Customizations for secondary y-axis\n",
    "#ax2.set_ylabel(color='lightcoral')\n",
    "ax2.legend(loc='upper right', frameon=True)\n",
    "\n",
    "# Aligning grid and layout\n",
    "plt.title('Explanation scores')\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig('Syn_Experiment1.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999435782949371"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim = lambda a,b : np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "\n",
    "cos_sim(gs_plot,ig_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 2] [1.96747666 1.42143353 1.56826515]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.ind, dataset.severity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
