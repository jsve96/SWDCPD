getwd()
getwd()
dirname(getwd())
datasetpath <- paste(dirname(getwd()),"datasets\has2023DataR")
datasetpath <- paste(dirname(getwd()),"datasets\has2023DataR",sep="")
current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"datasets\has2023DataR",sep="")
current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"datasets/has2023DataR",sep="")
print(datasetpath)
current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"datasets/has2023DataR/HASC_TS_",sep="")
print(datasetpath)
IDs = list(10,14,7,182,225,19,185,33,36,87,88,210,11,20,23,243,247,91,95,96,100,141,91,95,245)
lol <- list()
for (id in IDs){
print(id)
string = paste(paste(datasetpath,id,sep = ""),'.csv',sep="")
X<-  read.csv(string)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
res <- e.divisive(datapts,R=199,min.size = 500)
end_time <- Sys.time()
print(end_time - start_time)
print(res$estimates)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- res$estimates
print(lol)
#hashmap$id_c <- res$estimates
}
current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"/datasets/has2023DataR/HASC_TS_",sep="")
print(datasetpath)
IDs = list(10,14,7,182,225,19,185,33,36,87,88,210,11,20,23,243,247,91,95,96,100,141,91,95,245)
lol <- list()
for (id in IDs){
print(id)
string = paste(paste(datasetpath,id,sep = ""),'.csv',sep="")
X<-  read.csv(string)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
res <- e.divisive(datapts,R=199,min.size = 500)
end_time <- Sys.time()
print(end_time - start_time)
print(res$estimates)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- res$estimates
print(lol)
#hashmap$id_c <- res$estimates
}
library(ecp)
library(hash)
current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"/datasets/has2023DataR/HASC_TS_",sep="")
print(datasetpath)
IDs = list(10,14,7,182,225,19,185,33,36,87,88,210,11,20,23,243,247,91,95,96,100,141,91,95,245)
lol <- list()
for (id in IDs){
print(id)
string = paste(paste(datasetpath,id,sep = ""),'.csv',sep="")
X<-  read.csv(string)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
res <- e.divisive(datapts,R=199,min.size = 500)
end_time <- Sys.time()
print(end_time - start_time)
print(res$estimates)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- res$estimates
print(lol)
#hashmap$id_c <- res$estimates
}
datapath <-  paste(dirname(getwd()),"/datasets/Ocxupancy/Occupancy.csv",sep="")
X <- read.csv(datapath)
datapath <-  paste(dirname(getwd()),"/datasets/Occupancy/Occupancy.csv",sep="")
X <- read.csv(datapath)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
res <- e.divisive(datapts,R=30,sig.lvl=0.05,min.size = 400)
library(ecp)
library(hash)
library(jsonlite)
zip_file <- paste(dirname(getwd()),"/datasets/MNISTSeq.zip",sep="")
# Extract the only file inside the ZIP to a temporary location
json_file <- unzip(zip_file, exdir = tempdir())
# Read the JSON file
json_data <- fromJSON(json_file)
zip_file <- paste(dirname(getwd()),"/datasets/MNISTSeq.zip",sep="")
json_file <- unzip(zip_file, exdir = tempdir())
data <- fromJSON(json_file)
#data <- fromJSON("C:/Users/Sven Jacob/Documents/Github/SWDCPD/ChangeDetection/data.json")
lol <- list()
id <- 0
for (subdata in data){
datapts<-subdata$data
print("CPS")
print(subdata$labels)
start_time <- Sys.time()
res <- e.divisive(datapts,R=199,sig.lvl = 0.05)
end_time <- Sys.time()
print(res$estimates)
print(end_time - start_time)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- res$estimates
id <- id+1
}
library(ocp)
library(jsonlite)
zip_file <- paste(dirname(getwd()),"/datasets/MNISTSeq.zip",sep="")
json_file <- unzip(zip_file, exdir = tempdir())
data <- fromJSON(json_file)
lol <- list()
id <- 0
for (subdata in data){
datapts<-subdata$data
print("CPS")
print(subdata$target)
start_time <- Sys.time()
fit <- onlineCPD(
datapts = datapts,                     # Your MNIST-like data (matrix with 784 columns)
oCPD = NULL,                           # No previous model
missPts = "none",                      # No missing points handling
hazard_func = function(x, lambda) {
const_hazard(x, lambda = 100)        # Constant hazard function with lambda = 200
},
probModel = list("g"),                 # Gaussian observation model
init_params = list(list(
m = rep(0.3, 784),                   # Mean vector of length 784
k = 0.01,                            # Scalar confidence in the mean
a = 0.01,                               # Scalar shape parameter for variance
b = 1e-4)),                           # Scalar scale parameter for variance
multivariate = TRUE,                   # Enable multivariate mode
cpthreshold = 0.5,                     # Threshold for detecting changepoints
truncRlim = 10^(-4),                   # Limit for truncating probabilities
minRlength = 1,                        # Minimum run length
maxRlength = 10^4,                     # Maximum run length
minsep = 1,                            # Minimum separation for changepoints
maxsep = 10^4,                         # Maximum separation for changepoints
timing = FALSE,                        # Disable timing output
getR = FALSE,                          # Don't return posterior probabilities
optionalOutputs = FALSE,               # Disable optional outputs
printupdates = FALSE                   # Don't print updates
)
end_time <- Sys.time()
print(end_time - start_time)
print(fit$changepoint_lists$maxCPs)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- fit$changepoint_lists$maxCPs
id <- id+1
}
library(ocp)
IDs = list(10,14,7,182,225,19,185,33,36,87,88,210,11,20,23,243,247,91,95,96,100,141,91,95,245)
lol <- list()
for (id in IDs){
print(id)
string = current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"/datasets/has2023DataR/HASC_TS_",sep="")
X<-  read.csv(string)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
fit<- onlineCPD(datapts, oCPD = NULL, missPts = "none",
hazard_func = function(x, lambda) { const_hazard(x, lambda = 100)
}, probModel = list("g"), init_params = list(list(m = 0, k = 10, a
= 0.1, b = 10)), multivariate = TRUE, cpthreshold = 0.5,
truncRlim = 10^(-4), minRlength = 1,
maxRlength = 10^4, minsep = 1, maxsep = 10^4, timing = FALSE,
getR = FALSE, optionalOutputs = FALSE, printupdates = FALSE)
end_time <- Sys.time()
print(end_time - start_time)
print(fit$changepoint_lists$maxCPs)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- fit$changepoint_lists$maxCPs
print(lol)
#hashmap$id_c <- res$estimates
}
library(ocp)
IDs = list(10,14,7,182,225,19,185,33,36,87,88,210,11,20,23,243,247,91,95,96,100,141,91,95,245)
lol <- list()
for (id in IDs){
print(id)
datasetpath <- paste(dirname(getwd()),"/datasets/has2023DataR/HASC_TS_",sep="")
X<-  read.csv(string)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
fit<- onlineCPD(datapts, oCPD = NULL, missPts = "none",
hazard_func = function(x, lambda) { const_hazard(x, lambda = 100)
}, probModel = list("g"), init_params = list(list(m = 0, k = 10, a
= 0.1, b = 10)), multivariate = TRUE, cpthreshold = 0.5,
truncRlim = 10^(-4), minRlength = 1,
maxRlength = 10^4, minsep = 1, maxsep = 10^4, timing = FALSE,
getR = FALSE, optionalOutputs = FALSE, printupdates = FALSE)
end_time <- Sys.time()
print(end_time - start_time)
print(fit$changepoint_lists$maxCPs)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- fit$changepoint_lists$maxCPs
print(lol)
#hashmap$id_c <- res$estimates
}
dirname(getwd())
library(ocp)
IDs = list(10,14,7,182,225,19,185,33,36,87,88,210,11,20,23,243,247,91,95,96,100,141,91,95,245)
lol <- list()
current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"/datasets/has2023DataR/HASC_TS_",sep="")
for (id in IDs){
print(id)
datasetpath <-  paste(paste(datasetpath,id,sep = ""),'.csv',sep="")
X<-  read.csv(string)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
fit<- onlineCPD(datapts, oCPD = NULL, missPts = "none",
hazard_func = function(x, lambda) { const_hazard(x, lambda = 100)
}, probModel = list("g"), init_params = list(list(m = 0, k = 10, a
= 0.1, b = 10)), multivariate = TRUE, cpthreshold = 0.5,
truncRlim = 10^(-4), minRlength = 1,
maxRlength = 10^4, minsep = 1, maxsep = 10^4, timing = FALSE,
getR = FALSE, optionalOutputs = FALSE, printupdates = FALSE)
end_time <- Sys.time()
print(end_time - start_time)
print(fit$changepoint_lists$maxCPs)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- fit$changepoint_lists$maxCPs
print(lol)
#hashmap$id_c <- res$estimates
}
print(datasetpath)
X<-  read.csv(string)
library(ocp)
IDs = list(10,14,7,182,225,19,185,33,36,87,88,210,11,20,23,243,247,91,95,96,100,141,91,95,245)
lol <- list()
current_dir <- getwd()
datasetpath <- paste(dirname(getwd()),"/datasets/has2023DataR/HASC_TS_",sep="")
for (id in IDs){
print(id)
datasetpath <-  paste(paste(datasetpath,id,sep = ""),'.csv',sep="")
X<-  read.csv(datasetpath)
datapts <- X[,-1]
print('Start')
start_time <- Sys.time()
fit<- onlineCPD(datapts, oCPD = NULL, missPts = "none",
hazard_func = function(x, lambda) { const_hazard(x, lambda = 100)
}, probModel = list("g"), init_params = list(list(m = 0, k = 10, a
= 0.1, b = 10)), multivariate = TRUE, cpthreshold = 0.5,
truncRlim = 10^(-4), minRlength = 1,
maxRlength = 10^4, minsep = 1, maxsep = 10^4, timing = FALSE,
getR = FALSE, optionalOutputs = FALSE, printupdates = FALSE)
end_time <- Sys.time()
print(end_time - start_time)
print(fit$changepoint_lists$maxCPs)
id_c <- as.character(id)
print(id_c)
lol[[id_c]] <- fit$changepoint_lists$maxCPs
print(lol)
#hashmap$id_c <- res$estimates
}
### Occupancy with normalization
datapath <-  paste(dirname(getwd()),"/datasets/Occupancy/Occupancy.csv",sep="")
X <- read.csv(datasetpath)
datapts <- X[,-1]
z_score_normalized <- t(apply(datapts, 1, function(row) (row - mean(row)) / sd(row)))
# Convert back to a data frame
z_score_normalized <- as.data.frame(z_score_normalized)
colnames(z_score_normalized) <- colnames(datapts)
rownames(z_score_normalized) <- rownames(datapts)
print('Start')
start_time <- Sys.time()
fit <- onlineCPD(
datapts = z_score_normalized,                     # Your MNIST-like data (matrix with 784 columns)
oCPD = NULL,                           # No previous model
missPts = "none",                      # No missing points handling
hazard_func = function(x, lambda) {
const_hazard(x, lambda = 100)        # Constant hazard function with lambda = 200
},
probModel = list("g"),                 # Gaussian observation model
init_params = list(list(
m = rep(0.0, 4),                   # Mean vector of length 784
k = 0.01,                            # Scalar confidence in the mean
a = 0.01,                               # Scalar shape parameter for variance
b = 1e-4)),                           # Scalar scale parameter for variance
multivariate = TRUE,                   # Enable multivariate mode
cpthreshold = 0.5,                     # Threshold for detecting changepoints
truncRlim = 10^(-4),                   # Limit for truncating probabilities
minRlength = 1,                        # Minimum run length
maxRlength = 10^4,                     # Maximum run length
minsep = 1,                            # Minimum separation for changepoints
maxsep = 10^4,                         # Maximum separation for changepoints
timing = FALSE,                        # Disable timing output
getR = FALSE,                          # Don't return posterior probabilities
optionalOutputs = FALSE,               # Disable optional outputs
printupdates = FALSE                   # Don't print updates
)
end_time <- Sys.time()
print(end_time - start_time)
print(fit$changepoint_lists$maxCPs)
